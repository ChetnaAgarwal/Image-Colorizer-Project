{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image colorization project - flowers Part 1 - Web scraper.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFa9c0wAGZ17",
        "outputId": "523e31bc-ef11-4de7-e18f-d4830e9dd6f1"
      },
      "source": [
        "import os\n",
        "import requests # pip install requests #to sent GET requests\n",
        "from bs4 import BeautifulSoup # pip install bs4 #to parse html(getting data out from html, xml or other markup languages)\n",
        "\n",
        "# user can input a search keyword and the count of images required\n",
        "# download images from google search image\n",
        "Google_Image = \\\n",
        "    'https://www.google.com/search?site=&tbm=isch&source=hp&biw=1873&bih=990&'\n",
        "\n",
        "# The User-Agent request header contains a characteristic string \n",
        "# that allows the network protocol peers to identify the application type, \n",
        "# operating system, and software version of the requesting software user agent.\n",
        "# needed for google search\n",
        "u_agnt = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.54 Safari/537.36',\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
        "    'Accept-Encoding': 'none',\n",
        "    'Accept-Language': 'en-US,en;q=0.8',\n",
        "    'Connection': 'keep-alive',\n",
        "} #write: 'my user agent' in browser to get your browser user agent details\n",
        "\n",
        "Image_Folder = '/content/drive/MyDrive/Image colorizer/new_flowers'\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(Image_Folder):\n",
        "        os.mkdir(Image_Folder)\n",
        "    download_images()\n",
        "\n",
        "def download_images():\n",
        "    data = input('Enter your search keyword: ')\n",
        "    num_images = int(input('Enter the number of images you want: '))\n",
        "    \n",
        "    print('Searching Images....')\n",
        "    \n",
        "    search_url = Google_Image + 'q=' + data #'q=' because its a query\n",
        "    \n",
        "    # request url, without u_agnt the permission gets denied\n",
        "    response = requests.get(search_url, headers=u_agnt)\n",
        "    html = response.text #To get actual result i.e. to read the html data in text mode\n",
        "    \n",
        "    # find all img where class='rg_i Q4LuWd'\n",
        "    b_soup = BeautifulSoup(html, 'html.parser') #html.parser is used to parse/extract features from HTML files\n",
        "    results = b_soup.findAll('img', {'class': 'rg_i Q4LuWd'})\n",
        "    \n",
        "    #extract the links of requested number of images with 'data-src' attribute and appended those links to a list 'imagelinks'\n",
        "    #allow to continue the loop in case query fails for non-data-src attributes\n",
        "    count = 0\n",
        "    imagelinks= []\n",
        "    for res in results:\n",
        "        try:\n",
        "            link = res['data-src']\n",
        "            imagelinks.append(link)\n",
        "            count = count + 1\n",
        "            if (count >= num_images):\n",
        "                break\n",
        "            \n",
        "        except KeyError:\n",
        "            continue\n",
        "    \n",
        "    print(f'Found {len(imagelinks)} images')\n",
        "    print('Start downloading...')\n",
        "\n",
        "    for i, imagelink in enumerate(imagelinks):\n",
        "        # open each image link and save the file\n",
        "        response = requests.get(imagelink)\n",
        "        \n",
        "        imagename = Image_Folder + '/' + data + str(i+1) + '.jpg'\n",
        "        with open(imagename, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "\n",
        "    print('Download Completed!')\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "# code explanation : https://www.youtube.com/watch?v=8AyKJxBxx0M&t=172s"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your search keyword: orchids\n",
            "Enter the number of images you want: 80\n",
            "Searching Images....\n",
            "Found 80 images\n",
            "Start downloading...\n",
            "Download Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4Ila5Do758e"
      },
      "source": [
        "1. roses\n",
        "2. lilies\n",
        "3. Carnations\n",
        "4. Daisies\n",
        "5. Orchids\n",
        "6. Tulips\n",
        "7. Poppies\n",
        "8. Chrysanthemum\n",
        "9. Dahlias\n",
        "10. Lavender\n",
        "11. Iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCTpXf0JHnED"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}